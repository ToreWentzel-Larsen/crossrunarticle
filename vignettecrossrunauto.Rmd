---
title: "crossrunauto: A function for the Joint Distribution of Number of Crossings and  
  Longest Run in Autocorrelated Bernoulli Observations"
shorttitle: "crossrunauto"
author: 
- name: Tore Wentzel-Larsen  
  affiliation: 
    - Centre for Child and Adolescent Mental Health, Eastern and Southern Norway;
     Norwegian Centre of Violence and Traumatic Stress Studies 
  email: tore.wentzellarsen@gmail.com
- name: Jacob Anhøj
  affiliation: 
  - Rigshospitalet, University of Copenhagen, Denmark
  email: jacob@anhoej.net
package name: crossrun
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse  = TRUE, 
  comment   = "#>",
  fig.width = 7.15,
  fig.height = 3.5,
  echo = FALSE,
  message = FALSE)

library(crossrun)
```

## Introduction

For notation and setting here, see the vignette and defining articles for the package crossrun (references will be inserted, for the moment the references are kept as in the crossrun vignette). The functions in the package crossrun assume independent observations. Autocorrelation may lead to false alarms when using the Anhøj rules or variants of them, and it may be of some importance to investigate the extent of this problem. For that purpose we have developed a function crossrunauto that finds the joint distribution of C and L in a simple model for an autocorrelated sequence of Bernoulli observations. We first present the model, next we give formulas for the joint distribution in the model, present the function crossrunauto and finally show how the function may be checked by comparison with simulations.

## The model

The first observation has a simple Bernoulli distribution, $P (X_1=1)=p, P(X_1=0)=1-p$. We assume that the distribution of each subsequent observation is fully determined by the previous observation. Specifically, stated only for the first two observations we denote $d=P(X_2=0 \mid X_1=1)$, the "down" probability and $u=P(X_2=1 \mid X_1=0)$, the "up" probability. We first find the condition for the same distribution for all subsequent observations, this will hereafter be assumed. The condition is $P(X_2=1)=p$ which gives $$P(X_2=1 \mid X_1=1) \cdot P(X_1=1) + P(X_2=1 \mid X_1=0) \cdot P(X_1=0)=p$$
that gives $(1-d)p+u(1-p)=p$ or simplified $pd=(1-p)u$. It is easy to check that the same condition is obtained starting with the equivalent condition $P(X_2=0)=1-p$. This condition represents a line through the origin in the (d,u) plane, with slope $\frac{p}{1-p}$ that is >1 if p>1/2 and <1 if p>1/2. The slope is 1 in the symmetric case p=1/2, in that case the down and up probabilities are equal.

The condition for independent observations is that $$P(X_2=1 \mid X_1=1)=P(X_2=1 \mid X_1=0), 1-d=u$$
Together with the constancy condition $pd=(1-p)u$ this gives $d=1-p, u=p$. The autocorrelation k between two subsequent observations may be computed as $k=1-\frac{d}{1-p}=1-\frac{u}{p}$. Thus this is a model in which independence is equivalent to uncorrelated subsequent observations.

The main interest in the joint distribution of C and L may be in the symmetric case, but the procedure outlined here is quite general, only assuming the constancy condition. We first investigate the possible values of the down and up probabilities. If p>0.5, the constancy condition $pd=(1-p)u$ means that $d=\frac{1-p}{p}u$. This implies that all values $0 \leq u \leq 1$ of the up probability u are possible, but if u=1 the down probability is $d=\frac{1-p}{p}$ which is the maximum possible value of the down probability if p>1/2. Similarly, if p<0.5 all values $0 \leq u \leq 1$ of the down probability d are possible, but if d=1 the up probability is $u=\frac{p}{1-p}$ which is the maximum possible value of the up probability if p>1/2. In the function crossrunauto only the unconstrained change probability is included as an argument changeprob, this is u if $p \geq 0.5$ and d if p<0.5. The other change probability is then computed from the constancy condition $pd=(1-p)u$.

## The iterative procedure

The iterative procedure for computing the joint probabilities for C and L in the model defined above is now nearly the same as for independent observations. We still condition on S and F, where S is the first observation. $P_n(S=1)=p, P_N)S=0)=1-p$. And we still partion by the end F of the first crossing, with values $f=2, \ldots , n$ and an additional value 1 conventially definned as no crossing. Then  $$P_n(F=1 \mid S=1)=(1-d)^{n-1}, P_n(F=1 \mid S=0)=(1-u)^{n-1}$$
and for $f=2, \ldots , n$, $$P_n(F=f \mid S=1)=(1-d)^{f-2} \cdot d$$ $$P_n(F=f \mid S=0)=(1-u)^{f-2} \cdot u$$
The joint distribution may now be computed by an iterative procedure closely related to the procedure for independent observations, $$P_n (L=l,C=c \mid S=1) = \sum_{f=1}^n P_n(L=l,C=c \mid S=1,F=f) \cdot P_n (F=f \mid S=1)$$ $$P_n (L=l,C=c \mid S=0) = \sum_{f=1}^n P_n(L=l,C=c \mid S=0,F=f) \cdot P_n (F=f \mid S=0)$$
Here the last factors $P_n (F=f \mid S=1), P_n (F=f \mid S=0)$ are given above, with formulas only slightly different from the independent case. And the first factors, $P_n(L=l,C=c \mid S=1,F=f), P_n(L=l,C=c \mid S=0,F=f)$ are now, exactly as in the independet case, determined by the last n-f+1 observations, that still constitute a sequence of the same type as the full sequence, only that it is conditioned on the opposite starting position. For this argument the constancy assumption is crucial, each observation has the same success probability p. Just as in the independent case the probabilities may be re

## Old stuff, to be removed

In n independent Bernoulli observations with success probability p and failure probability q=1-p, values are denoted by 1 (success, with probability p) or 0. A crossing consists of two consecutive different values, and a run of length $l$ consists of $l$ successive observations, delimited by a crossing or the first or last observation. The possible values of the number C of crossings are $c=0, \ldots ,n-1$ and the possible values for the length L of the longest run are $l=1, \ldots ,n$. The joint probabilities of L and C for given n are denoted by $P_n (L=l,C=c)$.

The iterative procedure involves conditioning on the first observation denoted by S, with values 1 for success (probability p) and 0 for failure (probability q). What are computed in the iterative procedure are the conditional probabilities $$P_n (L=l,C=c \mid S=1), P_n (L=l,C=c \mid S=0)$$

This conditioning on the first observation is an essential part of the procedure. One way to see that this is reasonable is to consider the case when p is close to 1. Then most observations are successes, most runs are success runs and the conditional joint distribution of runs and crossings is quite different dependent on the first observation. It is sufficient to be able to compute these conditional distributions, because the unconditional joint distribution is
$$P_n (L=l,C=c) = P_n (L=l,C=c \mid S=1) \cdot p + P_n (L=l,C=c \mid S=0) \cdot q$$

For the iterative procedure to work it is also necessary to take another variable into account, the first crossing. More precisely, we denote the end position of the first crossing by F, with values $f=2, \ldots ,n$. An additional value $f=1$ denotes, by convention, the case of no crossing. The joint probabilities for C and L conditional on S are partioned by further conditioning on F as detailed below. First we present the starting point of the iterative procedure, the conditional probabilities in  the rather redundant case with only one observation.


## The "times" representation of the joint distributions

As mentioned, the joint distributions are actually not computed as probabilities, but as probabilities times a multiplier whose default value is $2^{n-1}$. Optionally another multiplier $m^{n-1}$ could be used where $m$ is an argument (`mult`) to the function `crossrunbin`, but the default value should normally be used. This representation is shown in Table 1 for n = 14 and p = 0.5.

One may note that in Table 1 all probabilities are represented by integers in the "times" representation. This is a general phenomenon in the symmetric case, but not for success probabilities different from 0.5. In the symmetric case ([Anhøj and Vingaard Olesen (2014)](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0113825)) the number, C, of crossings has a binomial distribution with number of observations n - 1 and probability 0.5, and their marginal probabilities are just the binomial coefficients divided by $2^{n-1}$. Indeed, the row sums in the times representation are the binomial coefficients in the symmetric case. This will be explicated later in the case of n = 14.

When the success probability is not 0.5, the joint distribution is no longer represented by integers even in the times representation. This is illustrated below for n = 14 and success probability 0.6. 


In Table 2 the results are shown with one decimal. The cells different from 0 are the same as in the symmetric case, but the distribution centre has been shifted in the direction of longer runs and fewer crossings. 

The times representation may be advantageous for presentation because very small numbers are avoided. However, the main reason for using this representation is to enhance precision in the iterative computation procedure.

## The symmetric case: `crossrunsymm`

In the symmetric case the joint probabilities are, as illustrated in Table 1, stored as integers in the times representation. A separate function `crossrunsymm` is available in this case. The arguments, except the success probability, are the same as in the more general function `crossrunbin`, but the inner workings are somewhat simpler.

## Generalisation

In the case of variable success probability, a similar procedure is available and implemented in the function `crossrunchange`. In this procedure all arguments are as in `crossrunbin`, except that the success probability is replaced by a vector of length n with success probabilities for each of the n time points.

## Limitations

The main limitation of this method is that the procedure does only apply when the median is pre-specified, not when it is determined by the time series itself, which, in practice, is often the case when using run charts for real time process monitoring. Also, the procedure cannot be generalized to autocorrelated time sequences.

## Conclusions

The `crossrun` package is, to our knowledge the first software package that allows for the computation of joint probabilities of longest run and number of crossings in time series data. This is an important step forward, as previous work on the subject have only dealt with these parameters as independent entities. This work may form the basis of better tests for non-random variation in time series data than are currently available.

## References

1. Jacob Anhøj (2015). [Diagnostic value of run chart analysis: 
 Using likelihood ratios to compare run chart rules on simulated 
 data series](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0121349)
PLOS ONE 10 (3): e0121349.

1. Jacob Anhøj, Anne Vingaard Olesen (2014). [Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0113825). PLoS ONE 9(11): e113825.
 
1. Laurent Fousse, Guillaume Hanrot, Vincent Lefèvre, 
 Patrick Pélissier, Paul Zimmermann. (2007). [Mpfr: A multiple-precision 
 binary floating-point library with correct 
 rounding](http://doi.acm.org/10.1145/1236463.1236468)
ACM Trans. Math. Softw. 33 (2): 13. ISSN 0098-3500.

1. Martin Mächler (2018). [Rmpfr: R MPFR - Multiple Precision 
  Floating-Point Reliable](https://CRAN.R-project.org/package=Rmpfr)
R package version 0.7-0.

